# Конспект
## Chroma
- **Тип**: Open source, легковесная векторная база данных.
- **Популярность**: Большое комьюнити, простота использования.
- **Технологии**:
    - Хранение данных на основе SQLite.
    - Не поддерживает горизонтальное масштабирование (single instance).
    - Нет распределённости, в отличие от Milvus или Qdrant.
- **Поиск и фильтрация**:
    - Есть фильтрация и поиск по метаданным.
    - Фильтрация простая, не поддерживает вложенные структуры.
    - Ограничения фильтрации и поиска по метаданным не дают максимальной гибкости при работе с метаданными.
- **Алгоритмы поиска**:
    - Используется только один алгоритм — Hierarchical Navigable Small World (HNSW).
    - HNSW обеспечивает логарифмический поиск (аппроксимация поиска ближайших соседей).
- **Квантование**:
    - Не поддерживается квантование embeddings, хранящихся в базе.
- **Ограничения**:
    - Из-за своей простоты и отсутствия распределённости не подходит для случаев с высокой нагрузкой и продакшн-использования.
- **Use-case**:
    - Подходит для прототипов.
---
## Qdrant
- **Язык реализации**: Написана на Rust, что обеспечивает лучшую оптимизацию по памяти и безопасности.
- **Распределённость**:
    - Изначально построена как распределённая база данных.
    - Поддерживает шардирование и репликацию.
        - **Репликация**: одинаковые инстанции одной базы хранятся в нескольких местах.
        - **Шардирование**: общий объём данных (embeddings) делится на разные инстанции; при индексации происходит ребалансировка для равномерного распределения векторов.
- **Архитектура**:
    - Распределённый монолит — при горизонтальном масштабировании добавляется сразу весь instance, масштабируются все операции одновременно.
    - Нет возможности масштабировать отдельные типы операций (например, только чтение).
- **Алгоритмы поиска**:
    - Использует только один алгоритм аппроксимации поиска ближайших соседей — кастомную реализацию HNSW.
    - Может работать с объёмом данных, который превышает объём оперативной памяти (граф хранится на диске, в RAM подгружается по необходимости).
- **Фильтрация**:
    - Фильтрация по метаданным производится до поиска ближайших соседей (как и в Chroma).
    - Более гибкая фильтрация по метаданным, включая условия поиска хотя бы одного значения в массиве и др.
- **Квантование**:
    - Поддерживает квантование embeddings:
        - **Продуктовое квантование**: делит embeddings на сегменты, которые записываются в таблице.
        - **Скалярное квантование**: округление точности, например, с float32 до int8, что снижает объём памяти для хранения числа в 4 раза.
- **Use-case**:
    - Подходит для более production-ready решений по сравнению с Chroma.
---
## Milvus
- **Архитектура**:
    - Векторная база данных, построенная на микросервисах.
    - Каждый сервисный узел отвечает за отдельные операции: запись, чтение, поиск.
    - Масштабирование возможно по отдельным операциям: например, можно увеличить число узлов только для чтения или только для записи, в зависимости от нагрузки.
    - За счёт такой микросервисной архитектуры достигается высокая гибкость масштабирования.
    - В Qdrant такого нет: там масштабирование идёт за счёт увеличения числа инстансов, и все операции масштабируются одновременно (распределённый монолит).
- **Распределённость**:
    - Поддерживает шардирование и репликацию, что обеспечивает хорошую горизонтальную масштабируемость.
- **Алгоритмы поиска**:
    - Milvus не привязан к конкретной реализации алгоритма аппроксимации поиска ближайших соседей.
    - Поддерживаются любые современные алгоритмы: HNSW, FAISS, IVF.
- **Требования к развёртыванию**:
    - Из-за микросервисной архитектуры требуется определённая DevOps-компетенция для развёртывания и поддержки.
- **Use-case**:
    - Подходит для ещё более production-ready решений, чем Qdrant.
---
## Pinecone
- **Тип**: Проприетарное (SaaS) решение, в отличие от self-hosted баз данных (Chroma, Qdrant, Milvus).
- **Доступ**:
    - Доступно через API.
    - Использование — по подписке, оплата за сервис.
    - Вендор берет на себя все низкоуровневые настройки и обслуживание.
- **Масштабируемость**:
    - Поддерживает шардирование и репликацию.
    - Обеспечивает гибкую горизонтальную масштабируемость, все настройки выполняются через API.
- **Фильтрация и поиск**:
    - Поддерживает гибкую фильтрацию и поиск по метаданным, аналогично Qdrant.
- **Алгоритмы поиска**:
    - Конкретный алгоритм аппроксимации поиска ближайших соседей не раскрывается.
    - Скорее всего используется кастомная, адаптированная версия HNSW или другого графового алгоритма.
- **Use-case**:
    - Для тех, кому важна максимальная простота внедрения и отсутствие необходимости администрирования инфраструктуры.
---
## Weaviate
- **Язык реализации**: Написана на Go, что обеспечивает хорошую поддержку многопоточности.
- **Интерфейс**:
    - Использует интерфейс на основе GraphQL, а не REST.
    - Это даёт возможность строить более гибкие запросы и получать только необходимые поля данных.
- **Векторизация**:
    - Поддерживает построение эмбеддингов (векторизацию) внутри самой базы, в отличие от Qdrant, который ожидает на вход уже готовые эмбеддинги.
- **Cross-Reference**:
    - Поддерживает cross-функцию — объекты могут ссылаться друг на друга.
    - За счёт этого строится графовая структура связей между объектами.
    - Основная особенность — представление данных не просто как набор эмбеддингов, а как связанные объекты.
- **Распределённость**:
    - Поддерживает шардирование и репликацию, как и другие современные векторные базы данных.
- **Алгоритмы поиска**:
    - Реализует собственные алгоритмы аппроксимации поиска ближайших соседей, например, HNSW.
- **Use-case**:
    - Особенно хорошо подходит для наборов данных с явными связями (например, авторы книг и сами книги), а не только для плоских структур документов.
- **Ограничения**:
    - Несмотря на поддержку cross-ссылок, Weaviate не является полноценной графовой базой данных.
    - Наличие cross-ссылок позволяет строить некоторые knowledge-графы, но Weaviate не заменяет специализированные решения, такие как NEO4J, для реализации паттернов типа GraphRAG.
---
## PG-Vector
- **Тип**: Расширение для существующей базы данных PostgreSQL.
- **Особенности**:
    - Добавляет новые типы данных и функции для работы с векторами прямо в PostgreSQL.
    - Векторные данные могут храниться, например, в отдельных колонках таблиц.
- **Алгоритмы поиска**:
    - Для аппроксимации поиска ближайших соседей поддерживаются два алгоритма: HNSW и IVF (на выбор).
- **Use-case**:
    - Оптимально подходит для случаев, когда данные уже хранятся в структурированном (реляционном) виде в PostgreSQL.
    - Идеален для задач, где требуется интеграция векторного поиска с традиционными реляционными данными.


# Алгоритмы ANN

### Конспект: Алгоритм HNSW (Hierarchical Navigable Small World)
#### 1. Назначение и основная идея
* **Что это?** HNSW — это алгоритм для **аппроксимации поиска ближайших соседей (Approximate Nearest Neighbor, ANN)**.
* **Зачем нужен в RAG?** В RAG-системах он необходим, чтобы не перебирать все доступные документы (эмбеддинги) для поиска релевантного контекста. Прямой перебор имеет **линейную сложность `O(N)`**, что очень медленно для больших баз знаний.
* **Преимущество:** HNSW предлагает решение с **приближенно логарифмической сложностью `O(log N)`**, при этом обеспечивая высокую **полноту (recall)**, то есть находит действительно близких соседей.
#### 2. Структура: Иерархический граф
* **Основа:** Алгоритм строит графовую структуру, состоящую из нескольких иерархических слоев.
* **Нижний слой (Layer 0):** Самый плотный, содержит **все** эмбеддинги из базы знаний.
* **Верхние слои:** Прогрессивно более **разреженные**. Чем выше слой, тем меньше на нем узлов (эмбеддингов), но связи между ними более "дальние", как скоростные шоссе.
#### 3. Построение графа
1. **Построение иерархии:**
* При добавлении нового эмбеддинга мы сначала помещаем его на самый нижний слой (Layer 0).
* Далее для каждого следующего слоя мы "подбрасываем монетку": с определенной вероятностью эмбеддинг попадает на слой выше. Если "монетка" выпадает неудачно, то на этот и все последующие слои эмбеддинг уже не добавляется.
2. **Установка связей:**
* На каждом слое, где присутствует узел, для него строятся прямые связи (ребра) с его ближайшими соседями на **этом же слое**.
* Количество связей для каждого узла ограничено гиперпараметром `M`.
#### 4. Процесс поиска ближайшего соседа
Поиск — это итеративный спуск по иерархии.
1. **Старт:** Начинаем поиск на самом верхнем, разреженном слое. Находим узел, ближайший к нашему входному запросу. Этот узел становится точкой входа для следующего уровня.
2. **Спуск и жадный поиск:**
* Опускаемся на слой ниже, используя найденный узел как отправную точку.
* Запускаем **жадный алгоритм**:
* Оцениваем всех соседей, с которыми у текущего узла есть прямые рёбра.
* Если находится сосед с **минимальным расстоянием** до запроса, которое меньше, чем у текущего узла, мы **переходим к нему**. Это становится новой отправной точкой, и итерация поиска повторяется.
* Если же ни один из прямых соседей не оказался ближе к цели, значит, мы **нашли локальный минимум**. Поиск на этом слое завершен.
3. **Финал:** Процесс повторяется, пока мы не дойдем до самого нижнего слоя (Layer 0). Узел, найденный на последнем шаге, и будет результатом приблизительного поиска ближайшего соседа.
#### 5. Добавление нового эмбеддинга в граф
1. **Определение уровня:** Сначала для нового эмбеддинга случайным образом определяется максимальный слой, на котором он будет присутствовать ("подбрасывание монетки").
2. **Поиск места:** Начиная с верхнего слоя, алгоритм ищет наиболее подходящее "место" для вставки, спускаясь вниз и находя на каждом уровне ближайших кандидатов в соседи.
3. **Установка и оптимизация связей:**
* Новый узел связывается с `M` ближайшими соседями на каждом из своих уровней.
* **Важная оптимизация:** Если у одного из этих соседей уже есть максимальное количество связей, он может **"отрубить" самую дальнюю связь**, чтобы установить новую, более близкую, с нашим добавляемым эмбеддингом. Это позволяет графу постоянно самосовершенствоваться.

### Конспект: Алгоритм IVF и Product Quantization
#### **Алгоритм IVF (Inverted File Index)**
**1. Основная цель:**
*   Это алгоритм для **аппроксимации поиска ближайших соседей** в RAG-системах.
*   Главная задача — избежать медленного полного перебора всех эмбеддингов (`brute-force`).
**2. Принцип работы: Построение индекса и поиск**
*   **Шаг 1: Индексация (заранее)**
    *   Мы изначально берём **весь наш набор данных** (все эмбеддинги) и кластеризуем его, как правило, с помощью алгоритма **k-средних (k-means)**.
    *   В алгоритм подается параметр `k` — желаемое число кластеров. В результате мы получаем `k` **центроидов**, которые являются "центрами" для каждой группы векторов.
*   **Шаг 2: Поиск (при поступлении запроса)**
    *   Когда мы хотим найти ближайшего соседа для нашего входного запроса, мы сначала считаем расстояние (например, косинусное) между **вектором запроса и всеми центроидами**.
    *   Затем для нескольких (`nprobe`) ближайших к запросу центроидов мы **перебираем уже все эмбеддинги, принадлежащие только этим кластерам**.
**3. Баланс "Скорость vs. Качество"**
*   Количество проверяемых ближайших кластеров (`nprobe`) — это настраиваемый параметр.
    *   **Уменьшаем параметр:** Берём меньше кластеров. Поиск работает **быстрее**, но качество (точность) может быть **ниже**.
    *   **Повышаем параметр:** Берём больше кластеров. Поиск становится **дольше**, но и качество **лучше**, так как мы проверяем больше потенциальных кандидатов.
---
#### **Оптимизация: Product Quantization (PQ)**
**1. Как работает кодирование вектора:**
*   **Разделение:** Каждый эмбеддинг в наборе данных делится на фиксированное количество **равных отрезков** (подвекторов), например, на 8.
*   **Отдельная кластеризация:** Для каждого из этих отрезков (точнее, для пространства, которое они занимают) проводится **своя** кластеризация.
*   **Кодирование:** Вектор кодируется таким образом, что вместо его фактического отрезка мы записываем **просто индекс ближайшего центроида** из соответствующего "словаря".
    *   *Практическая деталь:* Обычно для кластеризации отрезков берут `k=256` центроидов. Это позволяет закодировать индекс каждого центроида **одним байтом**. Таким образом, если вектор был разделен на 8 частей, его сжатая версия будет занимать всего **8 байт**.
**2. Как работает поиск с PQ:**
*   **Шаг 1: Подготовка запроса**
    *   Входной поисковый запрос **также делится на 8 частей**. Сам запрос остается несжатым (в float).
    *   Для **каждой части** запроса мы вычисляем расстояние до **каждого из 256 центроидов** в соответствующем словаре.
    *   В результате мы получаем **8 табличек**, где для каждого индекса центроида записано соответствующее расстояние.
*   **Шаг 2: Оценка расстояния до векторов в базе**
    *   Чтобы найти расстояние до любого сжатого вектора из нашей базы данных, мы делаем следующее:
        1.  Берём его сжатый код (например, 8 байт, где каждый байт — это индекс центроида).
        2.  Для **каждого индекса** в коде мы смотрим в **соответствующую ему табличку** и берем оттуда заранее вычисленное расстояние.
        3.  Все эти 8 найденных расстояний **складываем**.
*   **Результат:**
    *   **Чем меньше итоговая сумма расстояний, тем ближе входной запрос к соответствующему эмбеддингу из набора данных.**



### Конспект: FAISS — роль и позиционирование в экосистеме векторного поиска
**1. Определение и назначение**
*   **FAISS (Facebook AI Similarity Search)** — это высокопроизводительная библиотека с открытым исходным кодом, разработанная Meta AI.
*   **Основная функция:** Реализация алгоритмов для быстрого поиска по сходству (Similarity Search) и кластеризации в плотных векторах.
*   **Ключевая характеристика:** FAISS не является базой данных, а представляет собой **вычислительное ядро (computational core) / поисковый движок (search engine)**.
**2. Технологическая основа**
*   **Реализация:** Написана на C++ для максимальной производительности с официальными обертками (bindings) для Python.
*   **Поддерживаемые алгоритмы:**
    *   **Точный поиск (Exact Search):** `IndexFlatL2` (полный перебор, используется как эталон).
    *   **Приблизительный поиск ближайших соседей (Approximate Nearest Neighbor, ANN):**
        *   **IVF (Inverted File):** `IndexIVFFlat`, `IndexIVFPQ`. Метод основан на разделении пространства векторов на кластеры (ячейки Вороного) и поиске только внутри ближайших кластеров.
        *   **HNSW (Hierarchical Navigable Small World):** `IndexHNSW`. Метод основан на построении многослойного графа для быстрой навигации к ближайшим соседям.
        *   **Квантование (Quantization):** `Product Quantization (PQ)`. Метод сжатия векторов для уменьшения потребления памяти и ускорения вычисления расстояний за счет потери точности.
*   **Аппаратное ускорение:** Одна из ключевых особенностей FAISS — нативная поддержка вычислений на **GPU**, что позволяет достигать кратного прироста производительности в задачах индексации и поиска.
**3. FAISS в сравнении с векторными базами данных (Qdrant, Milvus, Chroma и др.)**
*   **FAISS — это библиотека, а не сервис.** Он не предоставляет:
    *   Сетевого API (REST/gRPC).
    *   Механизмов персистентного хранения данных и управления ими.
    *   CRUD-операций (удаление/обновление векторов затруднено для многих типов индексов).
    *   Фильтрации по метаданным.
    *   Встроенных инструментов для масштабирования, репликации и администрирования.
*   **Векторные БД — это полноценные системы.** Они используют поисковые движки (собственные или сторонние, как FAISS) и добавляют к ним всю вышеперечисленную функциональность, необходимую для промышленной эксплуатации.
**4. Использование FAISS в индустрии**
*   **Прямое использование:** Применяется в задачах, где требуется максимальный контроль над производительностью и ресурсами, в научных исследованиях и при быстром прототипировании локальных RAG-систем.
*   **Как компонент БД:**
    *   **Milvus:** Активно использует FAISS как один из основных поисковых движков в своем ядре **Knowhere**.
    *   **Большинство других БД (Qdrant, Weaviate, Chroma, Pinecone, pgvector):** **Не используют** FAISS. Они разрабатывают собственные реализации ANN-алгоритмов (преимущественно HNSW) на своих основных языках (Rust, Go, C++) для лучшей интеграции, контроля над производительностью, поддержки динамических данных и реализации специфических функций, таких как фильтруемый поиск.
**Вывод:**
FAISS является фундаментальной библиотекой, заложившей основы для современного векторного поиска. В контексте RAG он выступает либо как легковесный in-memory движок для прототипов, либо как внутренний компонент некоторых специализированных векторных БД (например, Milvus). Однако большинство современных векторных баз данных предпочитают собственные реализации для достижения большей гибкости, специализации и лучшей интеграции в свой технологический стек.

### **Конспект: Выбор ANN-алгоритма для проектирования RAG-системы**
#### **Введение: От "Карго-культа" к Инженерному Решению**
 Выбор ANN-алгоритма — это не выбор "лучшего" инструмента, а выбор набора **компромиссов**, которые оптимально подходят под вашу конкретную задачу. Простое следование тренду (например, "все используют HNSW") может привести к созданию неэффективной, дорогой или медленной системы. Этот гайд рассматривает ключевые факторы, влияющие на выбор между двумя основными парадигмами: **HNSW (графовый подход)** и **IVF (подход на основе кластеризации)**.
---
### **Два титана: HNSW vs. IVF. Краткая суть**
*   **HNSW (Hierarchical Navigable Small World):** Представьте социальную сеть. Чтобы найти человека, вы не спрашиваете всех подряд. Вы спрашиваете своих друзей, они — своих, и так вы быстро добираетесь до нужного человека через "шесть рукопожатий". HNSW строит многоуровневый граф, где поиск — это быстрый спуск по "хайвеям" связей к нужной области. **Девиз: быстрый прицельный поиск.**
*   **IVF (Inverted File):** Представьте огромную библиотеку, разделенную на залы по темам ("Финансы", "История", "Фантастика"). Чтобы найти книгу, вы сначала идете в нужный зал (кластер), а уже потом ищете на его полках. IVF делит все векторы на кластеры и при поиске смотрит только в нескольких самых релевантных. **Девиз: разделяй и властвуй.**
---
### **Ключевые Факторы для Принятия Решения**
#### 1. Фильтрация: Иллюзия "Pre-filtering" в HNSW
Это один из самых важных и неочевидных моментов.
*   **Настоящий Pre-filtering (подход IVF):**
    1.  **Сначала фильтр, потом поиск:** Система сначала отбирает всех кандидатов, подходящих под метаданные (например, `source = 'legal_docs'`).
    2.  **Поиск по подмножеству:** ANN-поиск запускается только по этому, уже отфильтрованному, небольшому набору данных.
    3.  **Результат:** Быстро и очень точно. Чем строже фильтр, тем быстрее поиск.
*   **Filtered Search (реальность HNSW):**
    1.  **Поиск и фильтр одновременно:** HNSW не может заранее отфильтровать данные, так как это сломает его навигационный граф. Вместо этого он начинает обход графа, и на каждом шаге проверяет узел: "Ты подходишь под фильтр?".
    2.  **Если узел не подходит:** Он отбрасывается, и алгоритм ищет обходной путь.
    3.  **Результат и компромиссы:**
        *   **Падение скорости:** Алгоритм "блуждает" по графу, отбрасывая 99% узлов. Чем строже фильтр, тем **медленнее** поиск.
        *   **Падение точности (Recall):** Самый релевантный для вас вектор может быть "спрятан" за узлом, который не проходит по фильтру. Алгоритм отбросит этот узел-мост и никогда не найдет вашу цель.
> **Вывод для RAG:** Если ваша система сильно зависит от точной и быстрой фильтрации по метаданным (например, RAG для разных клиентов в одной базе), **IVF** или продвинутые реализации HNSW (как в **Qdrant**) будут значительно эффективнее стандартного HNSW.
#### 2. Объем данных и Память: RAM vs. Диск
*   **Стандартный HNSW — это алгоритм для RAM.** Он предполагает, что весь граф связей и, в идеале, сами векторы находятся в оперативной памяти для максимальной скорости.
*   **Реальность:** Данных часто больше, чем RAM. Векторные БД решают эту проблему:
    *   **Квантизация (Quantization):** Самый популярный метод. Векторы сжимаются (например, из 32-битных чисел в 8-битные). Индекс HNSW остается в RAM, но ссылается на сжатые векторы на диске. Это радикально (в 4-30 раз) снижает требования к RAM ценой небольшой потери точности. **Qdrant** и **Milvus** отлично это умеют.
    *   **Гибридное хранение (Memory-mapped files):** HNSW-индекс хранится на диске, а ОС подгружает нужные части в память "на лету". Это позволяет работать с огромными индексами, но **значительно замедляет** поиск из-за задержек дискового ввода-вывода.
> **Вывод для RAG:** Не дайте себя обмануть. Если вы видите "HNSW для миллиарда векторов", знайте, что это работает только благодаря умным техникам вроде квантизации. При проектировании учитывайте, что вам нужна либо БД с поддержкой квантизации, либо сервер с огромным количеством RAM.
#### 3. Динамика Данных: Статический Архив vs. Живой Поток
*   **HNSW (для динамических данных):**
    *   **Добавление/удаление:** Очень эффективно. Добавление нового вектора — это локальная операция по установлению связей с ближайшими соседями. Удаление обычно происходит через пометку узла как "удаленного". Это не требует перестройки всего индекса.
*   **IVF (для статических данных):**
    *   **Добавление/удаление:** Добавлять векторы легко (просто положить в нужный кластер), но это постепенно "портит" индекс, делая центры кластеров неактуальными.
    *   **Переиндексация:** Чтобы поддерживать качество поиска, IVF-индекс необходимо **периодически полностью перестраивать** (запускать перекластеризацию). Это очень долгая и ресурсоемкая операция.
> **Вывод для RAG:**
> *   Если ваш RAG работает с постоянно обновляемыми данными (новости, чаты, логи), **HNSW** — ваш выбор.
> *   Если ваш RAG работает со статическим архивом (база юридических документов, научная библиотека), который обновляется раз в месяц, **IVF** будет отличным, экономичным и точным решением.
#### 4. Тип Нагрузки: Одиночные vs. Пакетные Запросы
*   **Одиночный запрос (Low Latency):** Цель — минимальное время ответа для одного пользователя.
    *   **HNSW — король этого режима.** Его навигация по графу идеально заточена под быстрый "спринт" к цели для одного запроса. Идеально для чат-ботов.
*   **Пакетный запрос (High Throughput):** Цель — обработать максимум запросов в секунду в офлайн-режиме.
    *   **IVF — чемпион этого режима.** Он может сгруппировать 1000 запросов, определить, какие кластеры им всем нужны, загрузить каждый нужный кластер в память **один раз** и "прогнать" по нему все релевантные запросы. Это гораздо эффективнее, чем 1000 раз бегать по графу HNSW. Идеально для аналитики.
> **Вывод для RAG:** Проектируете интерактивного помощника? **HNSW**. Проектируете систему для ночной аналитики и обогащения данных? **IVF**.
#### 5. Масштабируемость: Монолитность vs. Шардирование
*   **HNSW — по своей природе монолитен.** Его граф сложно "разрезать" на несколько машин.
    *   **Решение (как в Qdrant):** Архитектурный трюк **"Scatter-Gather"**. Данные делятся на шарды по ID. На каждом шарде строится свой **независимый** HNSW-индекс. Поисковый запрос отправляется **параллельно на все шарды**, а результаты потом собираются и объединяются. Это не распределенный граф, а федерация независимых графов.
*   **IVF — нативно масштабируемый.**
    *   Его кластеры — это независимые "куски" данных. Их можно легко разложить по разным машинам (шардам). Поиск идет только на тех машинах, где лежат нужные кластеры. Это простая и очень эффективная модель для распределенных систем.
> **Вывод для RAG:** Если вы планируете систему, которая будет расти до петабайтов и тысяч машин, архитектура на основе **IVF** может оказаться проще в реализации и поддержке. HNSW тоже масштабируется, но через более сложную архитектурную обертку.
---
### **Итоговая Сводка и Рекомендации**
| Критерий | HNSW (Qdrant, Weaviate) | IVF (Milvus, Faiss) |
| :--- | :--- | :--- |
| **Фильтрация** | ⚠️ **Filtered Search** (медленнее, ниже точность) | ✅ **True Pre-filtering** (быстро, точно) |
| **Динамика данных** | ✅ **Отлично** (быстрое добавление/удаление) | ⚠️ **Плохо** (требует дорогой переиндексации) |
| **Режим работы** | ✅ **Low Latency** (идеально для одиночных запросов) | ✅ **High Throughput** (идеально для пакетной обработки) |
| **Память (RAM)** | ⚠️ **Высокое** потребление | ✅ **Низкое** потребление (особенно с квантизацией) |
| **Масштабирование** | ⚠️ **Сложное** (монолит, требует "Scatter-Gather") | ✅ **Простое** (нативно шардируется по кластерам) |
**Когда выбирать HNSW:**
*   Вам нужна **минимальная задержка** для интерактивного RAG (чат-боты).
*   Данные **постоянно обновляются** (добавляются/удаляются).
*   Фильтрация не является основной или очень "жесткой" функцией.
*   Вы готовы платить за большое количество RAM или используете БД с продвинутой квантизацией (как Qdrant).
**Когда выбирать IVF:**
*   Ваша RAG-система работает со **статическими или редко обновляемыми** данными.
*   **Эффективная фильтрация** — критически важная часть вашей системы.
*   Основная нагрузка — **офлайн-обработка больших пакетов** запросов.
*   Вы строите **масштабную распределенную систему** и хотите минимизировать архитектурную сложность.
*   **Бюджет на RAM ограничен.**

# Конспект по пробелам в математике
## Евклидова норма (длина вектора)

* **Определение:**

Для вектора $a = (a_1, a_2, \ldots, a_d)$

$$

\|a\| = \sqrt{a_1^2 + a_2^2 + \dots + a_d^2}

$$

* Это расстояние от начала координат до точки-вектора.

---

## Нормализация вектора

* **Нормализация:**

$$

n = \frac{a}{\|a\|}

$$

* Превращает вектор в единичный (длина = 1), сохраняет направление.

---

## Направляющий и нормальный вектор

* **Направляющий вектор**: указывает направление линии/прямой.

* **Нормальный вектор**: перпендикулярен (ортогонален) прямой, плоскости или гиперплоскости.

* **Ортогональность:**

Два вектора $a$ и $b$ ортогональны, если $a \cdot b = 0$ (их скалярное произведение = 0).

---

## Гиперплоскость

* **Определение:**

В $d$-мерном пространстве:

$$

n \cdot x = d

$$

* $n$ — нормальный вектор (размерности $d$)

* $x$ — произвольная точка в пространстве

* $d$ — смещение (offset)

* **Размерность:**

В $d$-мерном пространстве гиперплоскость — объект размерности $d-1$ (например, плоскость в 3D, прямая в 2D).

* **Геометрический смысл:**

Все точки, удовлетворяющие уравнению, лежат на гиперплоскости.

Точки $n \cdot x > d$ и $n \cdot x < d$ — по разные стороны гиперплоскости.

---

## Построение дерева Annoy (RAG)

1. Для каждого дерева рекурсивно разбиваем множество векторов с помощью гиперплоскостей.

2. На каждом шаге выбираем два случайных вектора $u, v$, строим нормальный вектор:

$$

n = \frac{u - v}{\|u - v\|}

$$

Смещение (обычно через середину между $u$ и $v$):

$$

m = \frac{u + v}{2},\quad d = n \cdot m

$$

3. Для каждого вектора $w$ вычисляем $n \cdot w - d$ и относим его к одной из сторон гиперплоскости.

4. Повторяем процесс для каждой части, пока не достигнем “малого” количества векторов в листе.

5. В результате получаем дерево, которое быстро делит пространство на “близкие” группы векторов.

---

## Ключевые понятия

* **Гиперплоскость**: тождественно задаётся уравнением $n \cdot x = d$.

* **Нормальный вектор**: ортогонален гиперплоскости, определяет “направление разреза”.

* **Annoy**: использует случайные гиперплоскости для эффективного построения индекса поиска ближайших соседей.

---

## Полезные ассоциации

* “Перпендикулярный” = “ортогональный” (векторы с углом 90°, скалярное произведение = 0).

* Точка лежит на гиперплоскости ⇔ $n \cdot x = d$.

* Векторы в Annoy делятся по знаку $n \cdot x - d$: одна часть — слева, другая — справа.

---

## Определение стороны гиперплоскости для эмбеддинга в Annoy

* Для заданного эмбеддинга $w$ и гиперплоскости $n \cdot x = d$:

* **Вычисляем значение:** $s = n \cdot w - d$

* Если $s > 0$: эмбеддинг лежит по одну сторону гиперплоскости (например, “справа”)

* Если $s < 0$: по другую сторону (“слева”)

* Если $s = 0$: эмбеддинг лежит точно на гиперплоскости

* Это позволяет Annoy на каждом шаге рекурсивного обхода дерева выбрать, в какое поддерево спускаться при поиске ближайших соседей.

---

## Применение

* Annoy строит **много** таких деревьев, чтобы случайные разрезы позволяли быстро искать близкие эмбеддинги для RAG и других задач.

---

**Если нужен пример или визуализация — смотри подробности выше или задай вопрос!**


### Конспект алгоритма Annoy (на основе вашего понимания)

#### 1. Общая концепция и назначение

**Annoy (Approximate Nearest Neighbors Oh Yeah)** — это алгоритм для эффективного **приблизительного поиска ближайших соседей (ANN)**, широко применяемый в RAG-системах и рекомендательных сервисах. Его главная цель — радикально ускорить поиск в многомерном пространстве ценой небольшой и контролируемой потери точности.

#### 2. Процесс построения индекса: Лес случайных деревьев

*   **Статичность данных:** Фундаментальное требование Annoy — **статичный и неизменяемый набор данных**. В отличие от HNSW, где можно добавлять элементы "на лету", или IVF, где можно добавлять в существующие кластеры, Annoy требует **полной перестройки индекса** при любом изменении датасета.
*   **Рекурсивное бинарное разбиение:** Основа индексации — итеративное разделение пространства. На каждом шаге для текущего подмножества векторов:
    1.  Строится **случайная гиперплоскость**. Она определяется двумя случайно выбранными точками из подмножества.
    2.  Все векторы в подмножестве распределяются на две группы ("левую" и "правую") в зависимости от их положения относительно этой гиперплоскости.
*   **Условие остановки:** Этот рекурсивный процесс продолжается до тех пор, пока в каждом конечном подпространстве (листе дерева) количество векторов не станет меньше или равно заранее заданному параметру `k`.
*   **Построение Леса:** Процесс повторяется `T` (`n_trees`) раз на одном и том же исходном наборе данных. Поскольку гиперплоскости строятся случайно, каждое из `T` деревьев получается уникальным. Использование леса повышает вероятность нахождения истинных соседей, так как неудачное разбиение в одном дереве может быть скомпенсировано удачным в другом.

#### 3. Структура дерева: Узлы и Листья

Дерево состоит из двух типов элементов:

*   **Узел разделения (Internal Node):** Это "навигационный переключатель". Он **не хранит** никаких векторов данных. Его содержимое — это математическое описание гиперплоскости:
    *   **Нормальный вектор (`n`):** Определяет ориентацию плоскости.
    *   **Смещение (`d`):** Определяет её положение в пространстве.
    Его единственная функция — принять вектор `q` и направить его к левому или правому потомку на основе знака скалярного произведения `n · q - d`.

*   **Листовой узел (Leaf Node):** Это терминальная точка любой ветви. Он хранит список идентификаторов (ID) векторов, попавших в данное конечное подпространство.

#### 4. Процесс поиска (Inference): Навигация с приоритетной очередью

Поиск ближайших соседей для вектора запроса `q` — это не "жадный" спуск, а умное исследование с помощью **приоритетной очереди**:

*   **Механизм очереди:** В очередь добавляются узлы для будущего исследования. Приоритет узла — это "цена" пути к нему. **Чем меньше числовое значение приоритета, тем выше приоритет.**
*   **Исследование ветвей:** Когда алгоритм находится в узле разделения, он:
    1.  Определяет "ближнего" потомка (в чьё полупространство попал `q`) и "дальнего".
    2.  Добавляет "ближнего" потомка в очередь, сохраняя текущий приоритет пути.
    3.  Добавляет "дальнего" потомка, но с **увеличенным приоритетом**. Новый приоритет равен `текущий_приоритет + |margin|`, где `|margin|` — это расстояние от `q` до разделяющей гиперплоскости. Это "штраф" за выбор менее очевидного пути.
*   **Динамический путь:** Алгоритм всегда извлекает из очереди узел с наивысшим приоритетом. Это позволяет ему динамически переключаться между разными ветвями и даже разными деревьями, всегда исследуя самый перспективный на данный момент путь.
*   **Завершение поиска:**
    1.  Когда спуск доходит до **листового узла**, все ID из него добавляются в список кандидатов.
    2.  Процесс останавливается, когда общее число рассмотренных кандидатов превышает бюджет `search_k`.
    3.  Из итогового списка кандидатов выбираются топ-N ближайших с помощью точного расчета расстояния.

---

### Сравнение с HNSW и IVF

| Характеристика | Annoy | HNSW (Hierarchical Navigable Small World) | IVF (Inverted File) |
| :--- | :--- | :--- | :--- |
| **Аналогия** | Лес случайных карт | Система скоростных шоссе и городских улиц | Библиотечный каталог или индекс книги |
| **Основная идея** | Рекурсивное бинарное разбиение пространства. | Построение многослойного графа для быстрой навигации. | Кластеризация пространства и поиск только в релевантных кластерах. |
| **Динамичность** | **Нет.** Требует полной перестройки. | **Да.** Легко добавляет новые элементы в граф. | **Частично.** Можно добавлять элементы, но для оптимальной работы нужна периодическая перетренировка кластеров. |

#### Асимптотическая сложность поиска

*   **Annoy:** **`O(polylog(N))`**
    *   **Подробно:** Сложность определяется спуском по `T` деревьям, каждое из которых имеет глубину `O(log N)`. Дополнительная сложность вносится приоритетной очередью, зависящей от параметра `search_k`. Итоговая сложность поиска — `O(T * log N)` плюс накладные расходы на очередь. Поскольку `T` и `search_k` являются константами по отношению к `N`, сложность считается полилогарифмической. Это означает очень медленный рост времени поиска с увеличением размера датасета.

*   **HNSW:** **`O(log N)`**
    *   **Подробно:** Это теоретически самый эффективный из трех. Поиск начинается на самом разреженном верхнем слое графа, что позволяет за логарифмическое число шагов найти нужную область пространства. Затем происходит спуск по иерархии слоев (которых `O(log N)`), на каждом из которых выполняется жадный поиск по соседям. Благодаря свойствам "маленького мира", навигация на каждом слое также очень быстра. Совокупность этих факторов дает чистую логарифмическую сложность.

*   **IVF:** **`O(K + P * (N/K))`** , где `K` — число кластеров, `P` — число исследуемых кластеров.
    *   **Подробно:** Сложность состоит из двух частей. Первая — `O(K)` — это стоимость сравнения вектора запроса со всеми `K` центроидами для выбора `P` наиболее релевантных кластеров. Вторая — `O(P * (N/K))` — это стоимость полного перебора внутри этих `P` кластеров, в каждом из которых в среднем `N/K` векторов. При оптимальном выборе `K ≈ sqrt(N)`, общая сложность стремится к **`O(sqrt(N))`**. Хотя асимптотически это медленнее, чем `log N`, на практике IVF чрезвычайно быстр благодаря простой и легко распараллеливаемой структуре вычислений.